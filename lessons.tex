Having conducted various benchmarks of Spark Streaming for this research, we have found various parameters that can be used to tune the performance of the system. These parameters including the number of Receivers, the batch window size, the size of input records, and whether the input data is serialized. In this section we will describe in detail about their impacts on the end-to-end latency or throughput. While the termologies of these parameters are specific to Spark Streaming, we believe that they are in general applicable to stream processors that are distributed or follow the micro-batch model.

\paragraph{Number of Receivers}
In our synthetic benchmark using 20-byte records, a single Receiver is able to take in at most around 30MB/s, or 1.5M records/s, even after we modified the code to immediate drop instead of storing the data. While the throughput does not seem very high in terms of MBs, 1.5M records is 2.5 times the 600K records per second per node recorded by the original Spark Streaming paper. This insight tells us that when evaluating throughput of a system, both the volume of data as well as the size of input data should be taken into consideration.

To overcome the bottleneck in data intake, the solution can be as simple as increasing the number of receivers. It is also possible to obtain the performance gain by setting the number of Receivers larger than the number of physical machines. \joao{elaborate?}

\paragraph{Size of Input Records}
As explained by the previous subsection, the size of input records affect the system's performance in terms of throughput. As the size of the records increases, the throughput of the system in volume will also increase (\team{linearly?}) to a point. \team{need to show to what this point is}

\paragraph{Size of Batch Interval}
While the micro-batch approach increases throughput at the expense of latency by coalescing input data before processing, the size of the batch interval does not form a linear relationship with the throughput. In fact, the best latency is obtained when the batch interval is set to slightly larger than the time it takes to computationally process a batch. This difference accounts for overheads in task spawning, scheduling, and noise.

adaptive batching

\subsection{Input Serialization}
In Section 3, we evaluated the system using plain text input records. However, in real world applications, applications may choose to serialize their input data for better network latency. Serializing input data means they have to be deserialized during computation, so this decision concerns the trade-off between CPU and network I/O.

In the case of Spark Streaming, if the input data is serialized, it has the option to be directly stored inside the system as a block, bypassing the block interval and logic to convert stored records into blocks. Not surprisingly, this approach increases the rate at which Spark Streaming can intake data significantly. For the same benchmark with 20-byte records, Spark Streaming can sustain a throughput of 80MB/s, or 16M records per second using a single receiver.

The disadvantage of sending data direct as blocks is that they need to be coalesced at the application, i.e. the application needs to group input records together and send them as a block to Spark Streaming. This number should be relatively large: when Spark Stream receives blocks only containing single records, its throughput dropped to around 375KB/s, or 75K records/s.

%In this section we show that Spark Streaming is able to provide low end-to-end batch response times for a realistic and demanding workload. We also show that our contributions decrease the average batch latency by Y times and increases the scalability of the system from X tasks/s to Y tasks/s.

%In order to evaluate our contributions we have setup an instance of Spark Streaming to process a stream of tweets from Twitter. In our setup Spark Streaming runs in a dedicated cluster of 16 nodes. Each node has 16 cores  Intel IvyBridge 3.0GHz with 64GB of RAM. The nodes are interconnected with InfiniBand connections. We ran this experiment with 1 driver, 15 workers and X receivers.

%\paragraph {\bf Twitter Workload} To approximate as much as possible a real workload we have built a custom twitter receiver. This receiver listens for tweets using the standard Twitter API. Because this API samples the tweets (roughly 1\% of the tweets are published), every time we receive tweets from this 

What didn't look into: scheduling bottleneck, network bottleneck, complex workload, fault tolerance