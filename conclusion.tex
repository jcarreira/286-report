This paper presents an analysis of low-latency stream processing in Spark Streaming, a space that we have found this system lacking in practice.
We make three contributions to achieve this goal: 1) analysis of Spark Streaming performance, 2) identification of main bottlenecks in the system, and 3) design and evaluation optimizations to reduce overheads.

Much of this work is still in progress. We plan to continue working on this problem and evaluating the solutions we have proposed. 
