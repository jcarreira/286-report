From Figure~\ref{fig:SparkStreaming_time_breakdown}, we gained an understanding of how different components of the Spark Streaming architecture contribute to the end-to-end latency. In this section, we focus on optimizing two areas: the overhead of running tasks, and the time it takes for a Receiver to store a block and inform the Driver.

\subsection{Task Overheads}
According to Figure~\ref{fig:SparkStreaming_time_breakdown}, around 11\%, or 7.0ms is spent on average executing a task. However, since our synthetic benchmark performed near-trivial computation, most of the time spent in running the task is due to the overheads in running a task. 

To breakdown the process of running desks, we modified the Receiver so that it generated a block regardless of the number of records received. We then ran the system on empty input, using an application that required a single stage. The application is launched with 1 Receiver, running on the same machine as the Driver. Since there was no input, the computation itself was effectively a no-op. After profiling this workflow, we found that from the Driver's perspective, the average time of running a task, i.e. the time between the task is scheduled and the time between the result is received, was 5.0ms. The difference of 2.0ms was likely due to the fact that there was only 1 Receiver, running on the same machine as the Driver, under a very light load.

As we looked deeper into the 5.0ms, we found that approximately 3.6ms out of this time was in deserializing the task. These numbers suggest that if we can reduce the task deserialization time, there will be a considerable improvement to the overheads of running tasks.

\begin{figure}[t!]
 \begin{center}
   \includegraphics[scale=0.30]{images_graphs/deserialization.eps}
 \end{center}
 \caption{How a task is deserialized on the executor. Examples of new dependencies can be new libraries needed to run the current task.}
 \label{fig:deserialization}
\end{figure}

Having discovered that a significant portion of the time running small tasks is spent in deserialization, we further measured the time it took for individual components of deserialization to complete. Figure \ref{fig:deserialization} summarizes the process of task deserialization on the Executor. The Executor receives a task in the form of an array of bytes called \texttt{serializedTask}. This array is deserialized into a tuple of \texttt{taskFiles}, \texttt{taskJars}, and \texttt{taskBytes}, the first two of which are passed into a method called \texttt{updateDependencies()}, while the latter is further deserialized into a \texttt{task} object. The \texttt{task} object contains information such as the function to run, the RDD to use, and the partition of the RDD to operate on.

\begin{figure}[t!]
 \begin{center}
   \includegraphics[scale=0.60]{images_graphs/optimizations/graph2/task_deser_micro_illus.pdf}
 \end{center}
 \caption{Breakdown of average time spent deserializing a task before and after adding lazy instantiation of configuration object and caching task binaries.}
 \label{fig:deserialization_times}
\end{figure}

The left part of of Figure \ref{fig:deserialization_times} shows a time breakdown of deserialization. As can be seen in the graph, the majority of the time in this case is in updating dependencies and deserializing \texttt{taskBytes}. We next examine each of these two components in more detail.

\subsubsection{Update Dependencies}
In \texttt{updateDependencies()}, Spark creates a configuration object, and use it when dependencies need to be updated, for example to download additional libraries used by the task. However, this object is created regardless of whether new dependencies are introduced, and this objection creation is very costly in CPU cycles. Since a streaming application rarely introduces new dependencies once it starts to run, this method is incurring unnecessary costs. To solve this problem, we changed the object to be lazily instantiated, so that no cycles are wasted creating the configuration object unless new dependencies are introduced.

\subsubsection{Deserialize Binary}
In order to reduce the amount of duplicate data transferred, Spark wraps the function and the RDD of a task into a broadcast variable, and serializes the broadcast variable as a part of \texttt{taskBinary}. This way, those information are not sent a part of the task, but is pulled by the Executor when it reads the value of the broadcast variable. The advantage of broadcast variable is that once it is pulled by the Executor, the value of the variable is cached in its memory. Therefore, if multiple tasks in the Executor use the same function and RDD, only the first task will need to pull the information from the Driver, and the rest can read it from the cache, reducing network traffic.

This approach, however, is still too wasteful in a streaming environment. Similar to the rarity of new dependencies, the types of RDDs and functions to operate on them change little from batch to batch. With the current approach, one round trip is still required per batch to fetch the function and RDD, even though information could be derived from a previous batch. As the batch interval shrinks, this inefficiency becomes more apparent.

To eliminate this round trip, we experimented with caching of information on the functions and RDDs. The cache is implemented by keeping track of previously broadcasted information on the driver, and resend the previous broadcast variable if possible rather than creating a new one every time. Broadcast variables are automatically cached on the Executor side, so this methodology removes the extraneous communication with the Driver.

\subsection{Evaluation}
The improvements of the two optimizations described above are also shown in Figure \ref{fig:deserialization_times}. After the changes, deserialization time for a task decreased from 3.6ms to 0.2ms. The impact of the two changes on overall task runtime is reflected in Figure~\ref{fig:runtime_optimizations}.

\begin{figure}[t!]
 \begin{center}
   \includegraphics[scale=0.60]{images_graphs/optimizations/graph3/runtime_optimizations.pdf}
 \end{center}
 \caption{Average time spent in running no-op tasks before and after the optimizations in deserialization.}
 \label{fig:runtime_optimizations}
\end{figure}

To show the effect of reducing task runtimes, we performed a micro-benchmark running a single stage with many tasks. The results are shown in Figure \ref{fig:lazy_micro}.


\subsection{Limitations}
While caching task binaries sound simple in theory, they are more complicated to implement in practice. For example, in our implementation, the Driver caches the serialized binary of tasks. For serializations across batches to match, we made fields such as IDs that are unique across objects not be serialized. While this change does not affect correctness, it will complicate other components such as logging that uses those information.

Furthermore, our caching technique only works for batches with single stages. When there are multiple stages, i.e. when shuffles or aggregations are involved, the dependency in previous data tends to change from batch to batch, making it difficult to hit a previously cached binary.

In our experiments, we found that the rate at which the receiver can receive input is limited by the efficiency of the communication layer.
%does not increase significantly even if it drops every record.
Therefore, we did not treat this bottleneck as a fundamental architecture problem, and focused on scheduling and computation in our optimizations.

\begin{figure}[t!]
 \begin{center}
   \includegraphics[scale=0.50]{images_graphs/optimizations/graph1/lazy_micro.pdf}
 \end{center}
 \caption{Amount of time spent running a single Spark stage consisting of many tasks without and with lazy instantiation of configuration object.}
 \label{fig:lazy_micro}
\end{figure}
